[
{
	"uri": "https://alibaba.github.io/Dragonfly/api_reference/api_supernode/",
	"title": "APIs Provided by Supernode",
	"tags": [],
	"description": "",
	"content": "This topic explains how to use the APIs provided by Supernode. This section describes APIs that is provided by the supernode, aka cluster manager.\nRegistration POST /peer/registry  Parameters\nParameters are encodeds as application/x-www-form-urlencoded.\n cid: string, the client id. ip: ipv4 string, the client ip address. hostName: string, the host name of client node. superNodeIp: ipv4 string, the ip address of super node. port: integer, the port which client opens. callSystem: string, the caller identifier. version: string, client version. dfdaemon: boolean, tells whether it is a call from dfdaemon. path: string, the path which client can serve. rawUrl: string, the resource url provided by command line parameter. taskUrl: string, the resource url. md5: string, the md5 checksum for the resource, optional. identifier: string, identifer for the resource. headers: map, extra http headers sent to the raw url.  Under the scene, the cluster manager creates a new instance of Task, which is built from the information provided by parameters. Specifically, it generates a taskId based on rawUrl, md5 and identifier.\nThen the task would be saved in the memory state. At the same time, it will fetch extra information like the content-length which would generally be set. Also, the pieceSize is computed with the strategy below:\n if the total size is less than 200MB, the piece size would be 4MB by default. otherwise, the minimum of (${totalSize} / 100MB) + 2MB and 15MB.  The next step is, the peer information along with the task will be recorded:\n The peerwill be saved. The taskwill be saved.  The last step is about triggering a progress.\nResponse\nAn example response:\n{ \u0026quot;code\u0026quot;: 200, \u0026quot;data\u0026quot;: { \u0026quot;fileLength\u0026quot;: 687481, \u0026quot;pieceSize\u0026quot;: 4194304, \u0026quot;taskId\u0026quot;: \u0026quot;ba270626349198840d0255de8358b6c93fe6d57d922d036fbf40bcf3499f44a8\u0026quot; } }  Other cases could happen:\n the task id might duplicate with an existing one. 606 the url might be invalid. 607 the access requires authentication. 608 or 609  Get Task GET /peer/task  Parameters\nParameters are encoded as query string.\n superNode: ipv4 string, the ip address of super node. dstCid: string, destination client id. range: string, byte range. status: integer. result: integer. taskId: string, the task id. srcCid: string, the source client id.  The super node will analyze the status and result firstly:\n Running if status == 701. Success if status == 702 and result == 501. Fail if status == 702 and result == 500. Wait if status == 700.  In waiting status, the super node would:\n Save the status to be running.  In running status, the super node would will extract the piece status:\n Success if result == 501. Fail if result == 500. SemiSuc if result == 503.  (side note): result == 502 means invalid code.\nAnd update the progress for this specific task. Then it checks the status itself and also the peer status, after that, the super node will tell the client another task which has enough detail for the next piece, or fails if no one is available.\nResponse\nAn example resonse:\n{ \u0026quot;code\u0026quot;: 602, \u0026quot;msg\u0026quot;: \u0026quot;client sucCount:0,cdn status:Running,cdn sucCount: 0\u0026quot; }  This means the client has to wait, since no peer can serve this piece now. And if there is a peer which can serve this request, there will be a response like this:\n{ \u0026quot;code\u0026quot;: 601, \u0026quot;data\u0026quot;: [ { \u0026quot;cid\u0026quot;: \u0026quot;cdnnode:10.148.177.242~ba270626349198840d0255de8358b6c93fe6d57d922d036fbf40bcf3499f44a8\u0026quot;, \u0026quot;downLink\u0026quot;: \u0026quot;20480\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/qtdown/ba2/ba270626349198840d0255de8358b6c93fe6d57d922d036fbf40bcf3499f44a8\u0026quot;, \u0026quot;peerIp\u0026quot;: \u0026quot;10.148.177.242\u0026quot;, \u0026quot;peerPort\u0026quot;: 8001, \u0026quot;pieceMd5\u0026quot;: \u0026quot;d78ef0af9e95e880fa583b41cf5ad791:687486\u0026quot;, \u0026quot;pieceNum\u0026quot;: 0, \u0026quot;pieceSize\u0026quot;: 4194304, \u0026quot;range\u0026quot;: \u0026quot;0-4194303\u0026quot; } ] }  Peer Progress GET /peer/piece/suc  Parameters\nParameters are encoded as query string.\n dstCid: string, the destination client id. pieceRange: byte range. taskId: string, the task id. cid: string, the client id.  Response\nAn example response:\n{ \u0026quot;code\u0026quot;: 200, \u0026quot;msg\u0026quot;: \u0026quot;success\u0026quot; } "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/onboarding/",
	"title": "Before Starting",
	"tags": [],
	"description": "",
	"content": " Before getting started, let\u0026rsquo;s take a quick look at how to use this documentation portal of Dragonfly.\nNavigating With a rich set of navigation features, you can always locate your target resource at ease.\nNavigating to the Homepage To go to the homepage of the Dragonfly documentation portal, do one of the following:\n In the breadcrumb of any page, click Dragonfly. In the address bar of the browser, type https://alibaba.github.io/Dragonfly/ and press Enter.  Navigating to a Topic To navigate to a topic, do one of the following:\n In the left-side navigation pane, click a chapter title to expand this chapter, and then click a child topic. In the left-side navigation pane, click a chapter title, and then on the right-side reading pane, click the child topic link.  Navigating to a Specific Section of a Topic Some topics can be lengthy. To jump to a specific section, do the following:\n Hover-over the mini TOC icon in the breadcrumb.\n In the mini TOC overlay, click a section heading.\n  Navigating to Other Related Resources To navigate to other related resources, such as the Dragonfly roadmap, github repo, contributing guide, and so on, click the link under More in the left-side navigation pane.\nSearching Given that the Dragonfly documentation portal is a static website, you can find target information in a blink of an eye.\nTo perform a search, type your key words in the search box on the top of the left-side navigation pane, and matching results will appear in the overlay.\nIn the search results, click any link to jump to the topic, and your key words will be highlighted in yellow.\nImproving the Documentation If you see a typo, or just feel like adding your insights, don\u0026rsquo;t hesitate to click the Edit this page link in the breadcrumb. Then you\u0026rsquo;ll be prompted to sign in your Github account and fork the repository.\n"
},
{
	"uri": "https://alibaba.github.io/Dragonfly/user_guide/install_server/",
	"title": "Installing Server",
	"tags": [],
	"description": "",
	"content": "This topic explains how to install the Dragonfly server. For a data center or a cluster, we recommend that you use at least two machines with eight cores, 16GB RAM and Gigabit Ethernet connections for deploying supernodes.\n Context There are two layers in Dragonfly’s architecture: server (supernodes) and client (hosts). Install the supernodes in one of the following ways:\n Deploying with Docker: Recommended for quick local deployment and test. Deploying with physical machines: Recommended for production usage.  Prerequisites When deploying with Docker, the following conditions must be met.\n   Required Software Version Limit     Git 1.9.1+   Docker 1.12.0+    When deploying with physical machines, the following conditions must be met.\n   Required Software Version Limit     Git 1.9.1+   JDK 1.7+   Maven 3.0.3+   Nginx 0.8+    Procedure - When Deploying with Docker  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the project directory.\ncd Dragonfly  Build the Docker image.\n./build/build.sh supernode  Obtain the latest Docker image ID of the supernode.\ndocker image ls|grep 'supernode' |awk '{print $3}' | head -n1  Start the supernode.\n# Replace ${supernodeDockerImageId} with the ID obtained at the previous step docker run -d -p 8001:8001 -p 8002:8002 ${supernodeDockerImageId}   Procedure - When Deploying with Physical Machines  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the project directory.\ncd Dragonfly/src/supernode  Compile the source code.\nmvn clean -U install -DskipTests=true  Start the supernode.\n# If the 'supernode.baseHome’ is not specified, then the default value '/home/admin/supernode’ will be used. java -Dsupernode.baseHome=/home/admin/supernode -jar target/supernode.jar  Add the following configuration items to the Nginx configuration file.\nThe path of the Nginx configuration file is something like src/supernode/src/main/docker/sources/nginx.conf.\n server { listen 8001; location / { # Must be ${supernode.baseHome}/repo root /home/admin/supernode/repo; } } server { listen 8002; location /peer { proxy_pass http://127.0.0.1:8080; } }  Start Nginx.\nsudo nginx   After this Task  After the supernode is installed, run the following commands to verify if Nginx and Tomcat are started, and if Port 8001 and 8002 are available.\nps aux|grep nginx ps aux|grep tomcat telnet 127.0.0.1 8001 telent 127.0.0.1 8002  Install the Dragonfly client and test if the downloading works.\ndfget --url \u0026quot;http://${resourceUrl}\u0026quot; --output ./resource.png --node \u0026quot;127.0.0.1\u0026quot;  "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/overview/what_is_dragonfly/",
	"title": "What Is Dragonfly?",
	"tags": [],
	"description": "",
	"content": "Dragonfly is an intelligent P2P-based image and file distribution tool. It aims to improve the efficiency and success rate of file transferring, and maximize the usage of network bandwidth, especially for the distribution of larget amounts of data, such as application distribution, cache distribution, log distribution, and image distribution. At Alibaba, every month Dragonfly is invoked two billion times and distributes 3.4PB of data. Dragonfly has become one of the most important pieces of infrastructure at Alibaba.\nWhile container technologies makes DevOps life easier most of the time, it surely brings some challenges: for example the efficiency of image distribution, especially when you have to replicate image distribution on several hosts.\nDragonfly works extremely well with both Docker and PouchContainer in this scenario. It\u0026rsquo;s also compatible with containers of other formats. It delivers up to 57 times the throughput of native docker and saves up to 99.5% of the out bandwidth of registry.\nDragonfly makes it simple and cost-effective to set up, operate, and scale any kind of file, image, or data distribution.\nWhy Dragonfly This project is an open-source version of the Dragonfly used at Alibaba. It has the following features:\nMore Alibaba-internal features will be made available to open-source users soon. Stay tuned!\n  P2P-based file distribution: By using the P2P technology for file transmission, it makes the most out of the bandwidth resources of each peer to improve downloading efficiency, and saves a lot of cross-IDC bandwidth, especially the costly cross-board bandwidth. Non-invasive support to all kinds of container technologies: Dragonfly can seamlessly support various containers for distributing images. Host level speed limit: In addition to rate limit for the current download task like many other downloading tools (for example wget and curl), Dragonfly also provides rate limit for the entire host. Passive CDN: The CDN mechanism can avoid repetitive remote downloads. Strong consistency: Dragonfly can make sure that all downloaded files are consistent even if users do not provide any check code (MD5). Disk protection and highly efficient IO: Prechecking disk space, delaying synchronization, writing file blocks in the best order, isolating net-read/disk-write, and so on. High performance: Cluster Manager is completely closed-loop, which means that it doesn\u0026rsquo;t rely on any database or distributed cache, processing requests with extremely high performance. Auto-isolation of Exception: Dragonfly will automatically isolate exception nodes (peer or Cluster Manager) to improve download stability. No pressure on file source: Generally, only a few Cluster Managers will download files from the source. Support standard HTTP header: Support submitting authentication information through HTTP header. Effective concurrency control of Registry Auth: Reduce the pressure on the Registry Auth Service. Simple and easy to use: Very few configurations are needed.  How Does It Stack Up Against Traditional Solution? We carried out an experiment to compare the performance of Dragonfly and wget.\n   Test Environment      Dragonfly Server 2 * (24-Core 64GB-RAM 2000Mb/s)   File Source Server 2 * (24-Core 64GB-RAM 2000Mb/s)   Client 4-Core 8GB-RAM 200Mb/s   Target File Size 200MB   Experiment Date April 20, 2016    The expeirment result is as shown in the following figure.\nAs you can see in the chart, for Dragonfly, no matter how many clients are downloading, the average downloading time is always about 12 seconds. But for wget, the downloading time keeps increasing with the number of clients. When the number of wget clients reaches 1,200, the file source crashed and therefore cannot serve any client.\nHow Does It Work? Dragonfly works slightly differently when downloading general files and downloading container images.\nDownloading General Files The Cluster Manager is also called a supernode, which is responsible for CDN and scheduling every peer to transfer blocks between each other. dfget is the P2P client, which is also called \u0026ldquo;peer\u0026rdquo;. It\u0026rsquo;s mainly used to download and share blocks.\nDownloading Container Images Registry is similar to the file server above. dfget proxy is also called dfdaemon, which intercepts HTTP requests from docker pull or docker push, and then decides which requests to process with dfget.\nDownloading Blocks Every file is divided into multiple blocks, which are transmitted between peers. Each peer is a P2P client. Cluster Manager will check if the corresponding file exists in the local disk. If not, it will be downloaded into Cluster Manager from file server.\n"
},
{
	"uri": "https://alibaba.github.io/Dragonfly/cli_reference/dfdaemon/",
	"title": "dfdaemon",
	"tags": [],
	"description": "",
	"content": " dfdaemon This topic explains how to use the dfdaemon command.\nNAME dfdaemon - a proxy between pouchd/dockerd and registry used for pulling images.\nSYNOPSIS dfdaemon [options]\u0026hellip;\nOPTIONS -callsystem string caller name (default \u0026quot;com_ops_dragonfly\u0026quot;) -certpem string cert.pem file path -dfpath string dfget path (default is your installed path) -h\thelp -hostIp string dfdaemon host ip, default: 127.0.0.1 (default \u0026quot;127.0.0.1\u0026quot;) -keypem string key.pem file path -localrepo string temp output dir of dfdaemon (default is \u0026quot;${HOME}/.small-dragonfly/dfdaemon/data\u0026quot;) -maxprocs int the maximum number of CPUs that the dfdaemon can use (default 4) -notbs not try back source to download if throw exception (default true) -port uint dfdaemon will listen the port (default 65001) -ratelimit string net speed limit,format:xxxM/K -registry string registry addr(https://abc.xx.x or http://abc.xx.x) and must exist if dfdaemon is used to mirror mode -rule string download the url by P2P if url matches the specified pattern,format:reg1,reg2,reg3 -urlfilter string filter specified url fields (default \u0026quot;Signature\u0026amp;Expires\u0026amp;OSSAccessKeyId\u0026quot;) -v\tversion -verbose verbose  FILES Local Repository Directory The default local repository is: ${HOME}/.small-dragonfly/dfdaemon/data/, you can change it by setting the option: -localrep.\n"
},
{
	"uri": "https://alibaba.github.io/Dragonfly/user_guide/install_client/",
	"title": "Installing Client",
	"tags": [],
	"description": "",
	"content": "You have two options when installing the Dragonfly client: installing from the latest package, or installing from the source code. Installing from the Latest Package You can install from the latest packages we provided.\n Download a package of the client.\ncd $HOME # Replace ${package} with a package appropriate for your operating system and location wget ${package}  Available packages:\n If you\u0026rsquo;re in China:\n Linux 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_darwin_amd64.tar.gz\n  If you\u0026rsquo;re not in China:\n Linux 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_darwin_amd64.tar.gz\n   Unzip the package.\n# Replace `xxx` with the installation directory. tar -zxf df-client_0.2.0_linux_amd64.tar.gz -C xxx  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Replace `xxx` with the installation directory. # Execute or add this line to ~/.bashrc export PATH=$PATH:xxx/df-client/   Installing from the Source Code You can also install from the source code.\nYou must have installed Go 1.7+, and added the Go command to the PATH environment variable.\n Installing in $HOME/.dragonfly  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the target directory.\ncd Dragonfly  Install dfdaemon and dfget in $HOME/.dragonfly/df-client.\n./build/build.sh client  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Execute or add this line to ~/.bashrc export PATH=$HOME/.dragonfly/df-client:$PATH   Installing in Another Directory  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the target directory.\ncd Dragonfly/build/client  Install the client.\n./configure --prefix=${your_installation_directory} make \u0026amp;\u0026amp; make install  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Execute or add this line to ~/.bashrc export PATH=${your_install_directory}/df-client:$PATH   After this Task Test if the downloading works.\n```sh dfget --url \u0026quot;http://${resourceUrl}\u0026quot; --output ./resource.png --node \u0026quot;127.0.0.1\u0026quot; ``` "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/api_reference/api_preheat/",
	"title": "Preheat API",
	"tags": [],
	"description": "",
	"content": "This topic explains how to use the Preheat API. GET /api/check  check whether the connection to Dragonfly is available\n  Parameters Response: Content-type: application/json HTTP CodeResponse Body   200   { \u0026ldquo;code\u0026rdquo;: 200 }      POST /api/preheat  request to Dragonfly to start a preheat task\n  Parameters: Content-type: application/json Parameter TypeData Type  body  { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;image|file\u0026rdquo;, \u0026ldquo;url\u0026rdquo;: \u0026ldquo;\u0026lt;string\u0026gt;\u0026rdquo;, \u0026ldquo;header\u0026rdquo;: { \u0026ldquo;\u0026lt;name\u0026gt;\u0026ldquo;: \u0026ldquo;\u0026lt;value\u0026gt;\u0026ldquo; } } Dragonfly sends a request taking the \u0026lsquo;header\u0026rsquo; to the \u0026lsquo;url\u0026rsquo;.   If there is any authentication step of the remote server, the header should contain authenticated information.\nIf the type is image, then the url should be image url: \u0026lt;registry_host\u0026gt;/\u0026lt;image_name\u0026gt;:\u0026lt;image_tag\u0026gt;. Dragonfly will preheat the image according to registry API spec, the steps are: * construct manifest_url:\n ``` https://\u0026lt;harbor_host\u0026gt;/v2/\u0026lt;image_name\u0026gt;/manifests/\u0026lt;image_tag\u0026gt; ```   pull the manifest of the image from manifest_url get the fsLayers from manifest and construct layer_url of each layer:\n https://\u0026lt;harbor_host\u0026gt;/v2/\u0026lt;name\u0026gt;/blobs/\u0026lt;digest\u0026gt;  request these layer_urls above to handle any redirection response to get real downloading urls\n supernodes use these real downloading urls to preheat layers of this image\n Response: Content-type: application/json HTTP CodeResponse Body  200 Success response: { \u0026ldquo;code\u0026rdquo;: 200, \u0026ldquo;data\u0026rdquo;: { \u0026ldquo;taskId\u0026rdquo;: \u0026ldquo;\u0026lt;string\u0026gt;\u0026ldquo; } } Use \u0026lsquo;taskId\u0026rsquo; to query the status of the preheat task. 200 Error Response: { \u0026ldquo;code\u0026rdquo;: 400, \u0026ldquo;msg\u0026rdquo;: \u0026ldquo;\u0026lt;detailed error message\u0026gt;\u0026ldquo; }  \n  GET /api/preheat/{taskId}  query the current status of the preheat task which id is taskId\n  Response: Content-type: application/json HTTP CodeResponse Body  200 Success response: { \u0026ldquo;code\u0026rdquo;: 200, \u0026ldquo;data\u0026rdquo;: { \u0026ldquo;taskId\u0026rdquo;: \u0026ldquo;\u0026lt;string\u0026gt;\u0026rdquo;, \u0026ldquo;status\u0026rdquo;: \u0026ldquo;RUNNING|SUCCESS|FAIL\u0026rdquo; } }  200 Error Response: { \u0026ldquo;code\u0026rdquo;: 400, \u0026ldquo;msg\u0026rdquo;: \u0026ldquo;\u0026lt;detailed error message\u0026gt;\u0026ldquo; }   "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/overview/terminology/",
	"title": "Terminology",
	"tags": [],
	"description": "",
	"content": "This topic lists the common terms used throughout Dragonfly. Supernode Supernode is a long-time process with two primary responsibilities:\n It\u0026rsquo;s the tracker and scheduler in the P2P network that choose appropriate downloading net-path for each peer. It\u0026rsquo;s also a CDN server that caches downloaded data from source to avoid downloading same files repeatedly.  dfget Dfget is the client of Dragonfly used for downloading files. It\u0026rsquo;s similar to wget.\nAt the same time, it also plays the role of peer, which can transfer data between each other in P2P network.\ndfdaemon Dfdaemon is used for pulling images only. It establishes a proxy between dockerd/pouchd and registry.\nDfdaemon filters out layer fetching requests from all requests sent by dockerd/pouchd when pulling images, then uses dfget to downloading these layers.\n"
},
{
	"uri": "https://alibaba.github.io/Dragonfly/cli_reference/dfget/",
	"title": "dfget",
	"tags": [],
	"description": "",
	"content": " dfget This topic explains how to use the dfget command.\nNAME dfget - the client of Dragonfly, a non-interactive P2P downloader\nSYNOPSIS dfget -u [URL] [options]\u0026hellip;\nOPTIONS  -h, --help show this help message and exit --url URL, -u URL will download a file from this url --output OUTPUT, -O OUTPUT, -o OUTPUT output path that not only contains the dir part but also name part --md5 MD5, -m MD5 expected file md5 --callsystem CALLSYSTEM system name that executes dfget,its format is company_department_appName --notbs not back source when p2p fail --locallimit LOCALLIMIT, -s LOCALLIMIT rate limit about a single download task,its format is 20M/m/K/k --totallimit TOTALLIMIT rate limit about the whole host,its format is 20M/m/K/k --identifier IDENTIFIER, -i IDENTIFIER identify download task,it is available merely when md5 param not exist --timeout TIMEOUT, --exceed TIMEOUT, -e TIMEOUT download timeout(second) --filter FILTER, -f FILTER filter some query params of url ,e.g. -f 'key\u0026amp;sign' will filter key and sign query param.in this way,different urls correspond one same download task that can use p2p mode --showbar, -b show progress bar --pattern {p2p,cdn}, -p {p2p,cdn} download pattern,cdn pattern not support totallimit --version, -v version --node NODE, -n NODE specify nodes --console show log on console --header HEADER http header, e.g. --header=\u0026quot;Accept: *\u0026quot; --header=\u0026quot;Host: abc\u0026quot; --dfdaemon caller is from df-daemon  FILES /etc/dragonfly.conf default configuration file for dfget, it configures the address of the supernode.\n[node] address=127.0.0.1,127.0.0.2  ${HOME}/.small-dragonfly This directory is created by dfget when you first time start it.\n.small-dragonfly/ ├── data/ # stores temporary data downloaded by dfget ├── dfdaemon/ │ └── data/ # default, stores temporary data generated by dfdaemon ├── logs/ │ ├── dfclient.log # dfget's log file │ ├── dfserver.log # log file of peer server launched by dfget │ └── dfdaemon.log # dfdaemon's log file └── meta/ └── host.meta # stores meta information: peer server port  "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/user_guide/download_files/",
	"title": "Downloading Files",
	"tags": [],
	"description": "",
	"content": "Things are done differently when you download container images and download general files with Dragonfly. Prerequisites  You are using Linux operating system. You have installed Python 2.7+, and added the Python directory to the PATH environment variable. The supernode service is started.\nFor more information on the installation of supernodes, see Installing Server.\n   Downloading container images  Specify the supernodes.\na. Open the Dragonfly configuration file.\nvi /etc/dragonfly.conf  b. Add the IP of supernodes separated by comma to the configuration file.\n[node] address=nodeIp1,nodeIp2  Start the dfget proxy (dfdaemon).\n# Start dfdaemon and specify the image repo URL. The default port is `65001`. dfdaemon --registry https://xxx.xx.x # Review dfdaemon logs tailf ~/.small-dragonfly/logs/dfdaemon.log  To list all available parameters for dfdaemon, run dfdeaemon -h.\n  Configure the Daemon Mirror.\na. Modify the configuration file /etc/docker/daemon.json.\nvi /etc/docker/daemon.json  For more information on /etc/docker/daemon.json, see Docker documentation.\n b. Add or update the configuration item registry-mirrors in the configuration file.\n\u0026quot;registry-mirrors\u0026quot;: [\u0026quot;http://127.0.0.1:65001\u0026quot;]  c. Restart Docker daemon.\nsystemctl restart docker  Download an image with Dragonfly.\ndocker pull {imageName}  Don\u0026rsquo;t include the image repo URL in {imageName}, because the repo URL has been specified with the registry parameter when starting dfdaemon.\n   Downloading General Files  Specify the supernodes in one of the following ways.\n Specifying with the configuration file.\n# Open the Dragonfly configuration file. vi /etc/dragonfly.conf # Add the IP of supernodes separated by comma to the configuration file [node] address=nodeIp1,nodeIp2  Specifying with the parameter in the command line.\ndfget -u \u0026quot;http://www.taobao.com\u0026quot; -o /tmp/test.html --node nodeIp1,nodeIp2  When using this method, you must add the node parameter every time when you run the dfget command. And the parameter in the command line takes precedence over the configuration file.\n   Download general files with Dragonfly in one of the following ways.\n Download files with the default /etc/dragonfly.conf configuration.\ndfget --url \u0026quot;http://xxx.xx.x\u0026quot;  To list all available parameters for dfget, run dfget -h.\n  Download files with your specified supernodes.\ndfget --url \u0026quot;http://xxx.xx.x\u0026quot; --node \u0026quot;127.0.0.1\u0026quot;  Download files to your specified output file.\ndfget --url \u0026quot;http://xxx.xx.x\u0026quot; -o a.txt    After this Task To review the downloading log, run less ~/.small-dragonfly/logs/dfclient.log.\n"
},
{
	"uri": "https://alibaba.github.io/Dragonfly/overview/",
	"title": "Overview",
	"tags": [],
	"description": "",
	"content": "Get to know Dragonfly and the common terminologies.\n What Is Dragonfly?  Dragonfly is an intelligent P2P-based image and file distribution tool. It aims to improve the efficiency and success rate of file transferring, and maximize the usage of network bandwidth, especially for the distribution of larget amounts of data, such as application distribution, cache distribution, log distribution, and image distribution.  Terminology  This topic lists the common terms used throughout Dragonfly.  "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/user_guide/supernode_configuration/",
	"title": "Supernode Configuration",
	"tags": [],
	"description": "",
	"content": "The supernode is written in Java based on Spring Boot. You can easily set properties with command line parameters or with the configuration file. Supernode Properties    Property Name Default Value Description     supernode.baseHome /home/admin/supernode Working directory of the supernode   supernode.systemNeedRate 20 Network rate reserved for the system (Unit: MB/s)   supernode.totalLimit 200 Network rate reserved for the supernode (Unit: MB/s)   supernode.schedulerCorePoolSize 10 Core pool size of ScheduledExecutorService    Setting Properties You have two options when setting properties of a supernode.\n Setting properties with command line parameters.\njava -D\u0026lt;propertyName\u0026gt;=\u0026lt;propertyValue\u0026gt; -jar supernode.jar  Setting properties with the configuration file.\njava -Dspring.config.location=./config.properties,\u0026lt;otherConfigFilePath\u0026gt; -jar supernode.jar  "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/quick_start/",
	"title": "Quick Start",
	"tags": [],
	"description": "",
	"content": "Simply by starting a supernode in your Docker container, and installing the Dragonfly client, you can start downloading with Dragonfly. Prerequisites You have started your Docker container.\nStarting a Supernode in Your Docker Container  Pull the docker image we provided.\n# Replace ${imageName} with the real image name docker pull ${imageName}  Start a supernode.\n# Replace ${imageName} with the real image name docker run -d -p 8001:8001 -p 8002:8002 ${imageName}   We provided two images in different locations:\n China: registry.cn-hangzhou.aliyuncs.com/alidragonfly/supernode:0.2.0 US: registry.us-west-1.aliyuncs.com/alidragonfly/supernode:0.2.0  For example, if you\u0026rsquo;re in China, run the following commands:\ndocker pull registry.cn-hangzhou.aliyuncs.com/alidragonfly/supernode:0.2.0 docker run -d -p 8001:8001 -p 8002:8002 registry.cn-hangzhou.aliyuncs.com/alidragonfly/supernode:0.2.0  Installing Dragonfly Client  Download a package of the client.\ncd $HOME # Replace ${package} with a package appropriate for your operating system and location wget ${package}  Unzip the package.\ntar -zxf df-client_0.2.0_linux_amd64.tar.gz  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Execute or add this line to ~/.bashrc export PATH=$PATH:$HOME/df-client/   We provided different packages to suit your need. Please choose one and replace the ${package} with it.\n If you\u0026rsquo;re in China:\n Linux 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_darwin_amd64.tar.gz\n  If you\u0026rsquo;re not in China:\n Linux 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_darwin_amd64.tar.gz\n   For example, if you\u0026rsquo;re in China and using Linux, run the following commands:\ncd $HOME wget http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_linux_amd64.tar.gz tar -zxf df-client_0.2.0_linux_amd64.tar.gz # execute or add this line to ~/.bashrc export PATH=$PATH:$HOME/df-client/  Downloading a File with Dragonfly Once you have installed the Dragonfly client, you can use the dfget command to download a file.\ndfget -u 'https://github.com/alibaba/Dragonfly/blob/master/docs/images/logo.png' -o /tmp/logo.png  For more information on the dfget command, see dfget.\n Pulling an Image with Dragonfly  Start dfdaemon with a specified registry, such as https://index.docker.io.\nnohup dfdaemon --registry https://index.docker.io \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;  Add the following line to the dockerd configuration file /etc/docker/daemon.json.\n\u0026quot;registry-mirrors\u0026quot;: [\u0026quot;http://127.0.0.1:65001\u0026quot;]  Restart dockerd.\nsystemctl restart docker  Download an image with Dragonfly.\ndocker pull nginx:latest   Related Topics  Installing Server Installing Client Downloading Files supernode Configuration dfget "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/user_guide/",
	"title": "User Guide",
	"tags": [],
	"description": "",
	"content": "Understand how to use Dragonfly from installing the server and client to downloading files.\n Installing Server  This topic explains how to install the Dragonfly server.  Installing Client  You have two options when installing the Dragonfly client: installing from the latest package, or installing from the source code.  Downloading Files  Things are done differently when you download container images and download general files with Dragonfly.  Supernode Configuration  The supernode is written in Java based on Spring Boot. You can easily set properties with command line parameters or with the configuration file.  "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/cli_reference/",
	"title": "CLI Reference",
	"tags": [],
	"description": "",
	"content": "Understand the details of CLI commands.\n dfdaemon  dfdaemon This topic explains how to use the dfdaemon command. NAME dfdaemon - a proxy between pouchd/dockerd and registry used for pulling images. SYNOPSIS dfdaemon [options]\u0026hellip; OPTIONS -callsystem string caller name (default \u0026quot;com_ops_dragonfly\u0026quot;) -certpem string cert.pem file path -dfpath string dfget path (default is your installed path) -h\thelp -hostIp string dfdaemon host ip, default: 127.0.0.1 (default \u0026quot;127.0.0.1\u0026quot;) -keypem string key.pem file path -localrepo string temp output dir of dfdaemon (default is \u0026quot;${HOME}/.\n dfget  dfget This topic explains how to use the dfget command. NAME dfget - the client of Dragonfly, a non-interactive P2P downloader SYNOPSIS dfget -u [URL] [options]\u0026hellip; OPTIONS -h, --help show this help message and exit --url URL, -u URL will download a file from this url --output OUTPUT, -O OUTPUT, -o OUTPUT output path that not only contains the dir part but also name part --md5 MD5, -m MD5 expected file md5 --callsystem CALLSYSTEM system name that executes dfget,its format is company_department_appName --notbs not back source when p2p fail --locallimit LOCALLIMIT, -s LOCALLIMIT rate limit about a single download task,its format is 20M/m/K/k --totallimit TOTALLIMIT rate limit about the whole host,its format is 20M/m/K/k --identifier IDENTIFIER, -i IDENTIFIER identify download task,it is available merely when md5 param not exist --timeout TIMEOUT, --exceed TIMEOUT, -e TIMEOUT download timeout(second) --filter FILTER, -f FILTER filter some query params of url ,e.\n "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/api_reference/",
	"title": "API Reference",
	"tags": [],
	"description": "",
	"content": "Know the details of our APIs.\n APIs Provided by Supernode  This topic explains how to use the APIs provided by Supernode.  Preheat API  This topic explains how to use the Preheat API.  "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/faq/",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": " FAQ How can I pull images by Dragonfly See Use Dragonfly to Pull an Image\nHow can I download files by Dragonfly See Use Dragonfly to Download a File\nWhat is SuperNode SuperNode is a long-time process with two primary responsibilities:\n It\u0026rsquo;s the tracker and scheduler in the P2P network that choose appropriate downloading net-path for each peer. It\u0026rsquo;s also a CDN server that caches downloaded data from source to avoid downloading same files repeatedly.  What is dfget Dfget is the client of Dragonfly used for downloading files. It\u0026rsquo;s similar to using wget.\nAt the same time, it also plays the role of peer, which can transfer data between each other in p2p network.\nWhat is dfdaemon Dfdaemon is only used for pulling images. It establishes a proxy between dockerd/pouchd and registry.\nDfdaemon filters out layer fetching requests from all requests send by dockerd/pouchd when pulling images, then it uses dfget to downloading these layers.\n"
},
{
	"uri": "https://alibaba.github.io/Dragonfly/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://alibaba.github.io/Dragonfly/",
	"title": "Dragonfly",
	"tags": [],
	"description": "",
	"content": "       \nDragonfly is an intelligent P2P-based image and file distribution tool. It aims to improve the efficiency and success rate of file transferring, and maximize the usage of network bandwidth, especially for the distribution of larget amounts of data, such as application distribution, cache distribution, log distribution, and image distribution. At Alibaba, every month Dragonfly is invoked two billion times and distributes 3.4PB of data. Dragonfly has become one of the most important pieces of infrastructure at Alibaba.\nWhile container technologies makes DevOps life easier most of the time, it surely brings some challenges: for example the efficiency of image distribution, especially when you have to replicate image distribution on several hosts.\nDragonfly works extremely well with both Docker and PouchContainer in this scenario. It\u0026rsquo;s also compatible with containers of other formats. It delivers up to 57 times the throughput of native docker and saves up to 99.5% of the out bandwidth of registry.\nDragonfly makes it simple and cost-effective to set up, operate, and scale any kind of file, image, or data distribution.\nWhy Dragonfly? This project is an open-source version of the Dragonfly used at Alibaba. It has the following features:\nMore Alibaba-internal features will be made available to open-source users soon. Stay tuned!\n  P2P-based file distribution: By using the P2P technology for file transmission, it makes the most out of the bandwidth resources of each peer to improve downloading efficiency, and saves a lot of cross-IDC bandwidth, especially the costly cross-board bandwidth. Non-invasive support to all kinds of container technologies: Dragonfly can seamlessly support various containers for distributing images. Host level speed limit: In addition to rate limit for the current download task like many other downloading tools (for example wget and curl), Dragonfly also provides rate limit for the entire host. Passive CDN: The CDN mechanism can avoid repetitive remote downloads. Strong consistency: Dragonfly can make sure that all downloaded files are consistent even if users do not provide any check code (MD5). Disk protection and highly efficient IO: Prechecking disk space, delaying synchronization, writing file blocks in the best order, isolating net-read/disk-write, and so on. High performance: Cluster Manager is completely closed-loop, which means that it doesn\u0026rsquo;t rely on any database or distributed cache, processing requests with extremely high performance. Auto-isolation of Exception: Dragonfly will automatically isolate exception nodes (peer or Cluster Manager) to improve download stability. No pressure on file source: Generally, only a few Cluster Managers will download files from the source. Support standard HTTP header: Support submitting authentication information through HTTP header. Effective concurrency control of Registry Auth: Reduce the pressure on the Registry Auth Service. Simple and easy to use: Very few configurations are needed.  How Does It Stack Up Against Traditional Solution? We carried out an experiment to compare the performance of Dragonfly and wget.\n   Test Environment      Dragonfly Server 2 * (24-Core 64GB-RAM 2000Mb/s)   File Source Server 2 * (24-Core 64GB-RAM 2000Mb/s)   Client 4-Core 8GB-RAM 200Mb/s   Target File Size 200MB   Experiment Date April 20, 2016    The expeirment result is as shown in the following figure.\nAs you can see in the chart, for Dragonfly, no matter how many clients are downloading, the average downloading time is always about 12 seconds. But for wget, the downloading time keeps increasing with the number of clients. When the number of wget clients reaches 1,200, the file source crashed and therefore cannot serve any client.\nHow Does It Work? Dragonfly works slightly differently when downloading general files and downloading container images.\nDownloading General Files The Cluster Manager is also called a supernode, which is responsible for CDN and scheduling every peer to transfer blocks between each other. dfget is the P2P client, which is also called \u0026ldquo;peer\u0026rdquo;. It\u0026rsquo;s mainly used to download and share blocks.\nDownloading Container Images Registry is similar to the file server above. dfget proxy is also called dfdaemon, which intercepts HTTP requests from docker pull or docker push, and then decides which requests to process with dfget.\nDownloading Blocks Every file is divided into multiple blocks, which are transmitted between peers. Each peer is a P2P client. Cluster Manager will check if the corresponding file exists in the local disk. If not, it will be downloaded into Cluster Manager from file server.\nWho has adopted Dragonfly? Below are the adoptors of project Dragonfly. If you are using to Dragonfly to improve your distribution, please contact us with.\n\u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp;\nLicense Dragonfly is available under the Apache 2.0 License.\nCommercial Support If you need commercial support of Dragonfly, please contact us for more information: 云效.\nDragonfly is already integrated with AliCloud Container Services. If you need commercial support of AliCloud Container Service, please contact us for more information: Container Service \n"
},
{
	"uri": "https://alibaba.github.io/Dragonfly/roadmap/",
	"title": "Roadmap",
	"tags": [],
	"description": "",
	"content": " CNCF Ecosystem  Deploy SuperNode using Helm in Kubernetes Deploy dfget \u0026amp; dfdaemon using DaemonSet in Kubernetes Integration with Harbor: preheat image feature  Security  Support private container image Support authentication in SuperNode API Different encryption algorithm in data transmission  Efficiency  Dynamic downloading rate limiting and scheduling algorithm Use IPFS to share block datas between SuperNodes  Openness  Plug-In policy for CNCF projects Highly user-customized modules Refactor SuperNode with Golang  Scalability  Simplify the complexity of scaling SuperNodes in Kubernetes  Stability  Cluster the SuperNode to decrease possibility of failure  "
},
{
	"uri": "https://alibaba.github.io/Dragonfly/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]